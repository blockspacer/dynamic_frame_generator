\relax 
\citation{ref:monsters}
\@LN@col{1}
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}}
\newlabel{sec:introduction}{{I}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {I-A}}Problem Statement}{1}}
\newlabel{subsec:problem_statement}{{\unhbox \voidb@x \hbox {I-A}}{1}}
\@LN@col{2}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Level of detail in Pixar's ``Incredibles 2''.}}{1}}
\newlabel{fig:incredibles}{{1}{1}}
\citation{ref:frame_prediction}
\citation{ref:frame_prediction}
\citation{ref:spatiotemporal}
\citation{ref:spatiotemporal}
\citation{ref:spatiotemporal}
\citation{ref:posecnn}
\citation{ref:posecnn}
\citation{ref:pose_guided}
\@LN@col{1}
\@writefile{toc}{\contentsline {section}{\numberline {II}Related Concepts}{2}}
\newlabel{sec:related_concepts}{{II}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-A}}Applicable research}{2}}
\newlabel{subsec:applicable}{{\unhbox \voidb@x \hbox {II-A}}{2}}
\@LN@col{2}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Example of output frame and depth map of \cite  {ref:frame_prediction}.}}{2}}
\newlabel{fig:frame_prediction}{{2}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Example input and output frame of \cite  {ref:spatiotemporal}.}}{2}}
\newlabel{fig:spatiotemporal}{{3}{2}}
\citation{ref:pose_guided}
\citation{ref:spatiotemporal}
\citation{ref:pose_guided}
\citation{ref:pose_guided}
\citation{ref:pose_guided}
\@LN@col{1}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Example architecture for \cite  {ref:posecnn}.}}{3}}
\newlabel{fig:posecnn}{{4}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces System architecture proposed by \cite  {ref:pose_guided}.}}{3}}
\newlabel{fig:pose_guided}{{5}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-B}}Concepts from Complex Systems}{3}}
\newlabel{subsec:complex_systems}{{\unhbox \voidb@x \hbox {II-B}}{3}}
\@LN@col{2}
\@writefile{toc}{\contentsline {section}{\numberline {III}Architectural Overview}{3}}
\newlabel{sec:architecture}{{III}{3}}
\citation{ref:frame_prediction}
\citation{ref:pixelcnn_decoders}
\citation{ref:pixelcnn++}
\citation{ref:multi_source}
\citation{ref:image_captioning}
\citation{ref:posecnn}
\citation{ref:pose_guided}
\citation{ref:frame_prediction}
\citation{ref:pose_guided}
\citation{ref:pose_guided}
\citation{ref:pose_guided}
\citation{ref:pose_guided}
\@LN@col{1}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Project Considerations}{4}}
\newlabel{sec:considerations}{{IV}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-A}}A discussion on system inputs}{4}}
\newlabel{subsec:inputs}{{\unhbox \voidb@x \hbox {IV-A}}{4}}
\@LN@col{2}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Block diagram for proposed architecture.}}{4}}
\newlabel{fig:block_diagram}{{6}{4}}
\@LN@col{1}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-B}}Training The Algorithm}{5}}
\newlabel{subsec:training_the_algorithm}{{\unhbox \voidb@x \hbox {IV-B}}{5}}
\@LN@col{2}
\@writefile{toc}{\contentsline {section}{\numberline {V}Term Project Implementation Details}{5}}
\newlabel{sec:implementation}{{V}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {V-A}}Frame processing}{5}}
\newlabel{subsec:frame_processing}{{\unhbox \voidb@x \hbox {V-A}}{5}}
\@LN@col{1}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Frame processing comparision between 2 input frames.}}{6}}
\newlabel{fig:frame_processing}{{7}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {V-B}}Shadow image creation}{6}}
\newlabel{subsec:shadow_image_creation}{{\unhbox \voidb@x \hbox {V-B}}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Shadow image produced between input frames shown in Figure \ref  {fig:frame_processing}.}}{6}}
\newlabel{fig:shadow_image}{{8}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {V-C}}Frameblock selection}{6}}
\newlabel{subsec:frameblock_selection}{{\unhbox \voidb@x \hbox {V-C}}{6}}
\@LN@col{2}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Selected (red) and unselected (blue) frameblocks.}}{6}}
\newlabel{fig:shadow_roi}{{9}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {V-D}}Buffer frameblocks}{6}}
\newlabel{subsec:buffer_frameblocks}{{\unhbox \voidb@x \hbox {V-D}}{6}}
\@LN@col{1}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Example of a buffer frameblock.}}{7}}
\newlabel{fig:buffer_frameblock}{{10}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {V-E}}Validation of experimental data}{7}}
\newlabel{subsec:data_analysis}{{\unhbox \voidb@x \hbox {V-E}}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {V-F}}A study on the proposed machine learning models}{7}}
\newlabel{subsec:machine_learning}{{\unhbox \voidb@x \hbox {V-F}}{7}}
\@LN@col{2}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Comparison of complex (top) and simple (bottom) inputs.}}{7}}
\newlabel{fig:data_analysis}{{11}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Example of an artificial input for Generator II.}}{7}}
\newlabel{fig:generator_II}{{12}{7}}
\citation{ref:pix2pix_deblur}
\citation{ref:pix2pix}
\citation{ref:pix2pix_deblur}
\citation{ref:pix2pix_deblur}
\citation{posecnn}
\citation{ref:frame_prediction}
\citation{ref:spatiotemporal}
\citation{ref:posecnn}
\citation{ref:pose_guided}
\@LN@col{1}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {V-G}}Term project conclusions}{8}}
\newlabel{subsec:term_conclusions}{{\unhbox \voidb@x \hbox {V-G}}{8}}
\@LN@col{2}
\@writefile{toc}{\contentsline {section}{\numberline {VI}Future Work}{8}}
\newlabel{sec:future_work}{{VI}{8}}
\@writefile{toc}{\contentsline {section}{\numberline {VII}Conclusion}{8}}
\newlabel{sec:conclusion}{{VII}{8}}
\bibcite{ref:bessel_functions}{1}
\bibcite{ref:predictive_rendering}{2}
\bibcite{ref:frame_prediction}{3}
\bibcite{ref:image_captioning}{4}
\bibcite{ref:posecnn}{5}
\bibcite{ref:pixelcnn_decoders}{6}
\bibcite{ref:pixelcnn++}{7}
\bibcite{ref:multi_source}{8}
\bibcite{ref:pose_guided}{9}
\bibcite{ref:multi_view}{10}
\bibcite{ref:info_gan}{11}
\bibcite{ref:spatiotemporal}{12}
\bibcite{ref:monsters}{13}
\bibcite{ref:pix2pix}{14}
\bibcite{ref:pix2pix_deblur}{15}
\@LN@col{1}
\@writefile{toc}{\contentsline {section}{References}{9}}
\@LN@col{2}
\newlabel{app:a}{{VII}{10}}
\gdef\minted@oldcachelist{,
  default.pygstyle,
  default-pyg-prefix.pygstyle,
  5EC114E6017BCEB902008722C315D92F4AB05E2345D413E7B30750B717FAB843.pygtex,
  793C8CD353E041270A5D3189A53B4A6320A6F6841BA101A9CEBFF15CF8CD20AF.pygtex,
  4878786A075563BCB93375DB08815A754AB05E2345D413E7B30750B717FAB843.pygtex,
  CE17F98E150E07398AA971881126207320A6F6841BA101A9CEBFF15CF8CD20AF.pygtex}
\newlabel{app:b}{{VII}{14}}
